{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jnte5aYH3H6M"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy import stats\n",
        "import tensorflow as tf\n",
        "\n",
        "%matplotlib inline\n",
        "plt.style.use('ggplot')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def read_data(file_path):\n",
        "    column_names = ['user-id','activity','timestamp', 'x-axis', 'y-axis', 'z-axis']\n",
        "    data = pd.read_csv(file_path,header = None, names = column_names)\n",
        "    return data\n",
        "\n",
        "def feature_normalize(dataset):\n",
        "    mu = np.mean(dataset,axis = 0)\n",
        "    sigma = np.std(dataset,axis = 0)\n",
        "    return (dataset - mu)/sigma\n",
        "\n",
        "def plot_axis(ax, x, y, title):\n",
        "    ax.plot(x, y)\n",
        "    ax.set_title(title)\n",
        "    ax.xaxis.set_visible(False)\n",
        "    ax.set_ylim([min(y) - np.std(y), max(y) + np.std(y)])\n",
        "    ax.set_xlim([min(x), max(x)])\n",
        "    ax.grid(True)\n",
        "\n",
        "def plot_activity(activity,data):\n",
        "    fig, (ax0, ax1, ax2) = plt.subplots(nrows = 3, figsize = (15, 10), sharex = True)\n",
        "    plot_axis(ax0, data['timestamp'], data['x-axis'], 'x-axis')\n",
        "    plot_axis(ax1, data['timestamp'], data['y-axis'], 'y-axis')\n",
        "    plot_axis(ax2, data['timestamp'], data['z-axis'], 'z-axis')\n",
        "    plt.subplots_adjust(hspace=0.2)\n",
        "    fig.suptitle(activity)\n",
        "    plt.subplots_adjust(top=0.90)\n",
        "    plt.show()\n",
        "\n",
        "def windows(data, size):\n",
        "    start = 0\n",
        "    while start < data.count():\n",
        "        yield int(start), int(start + size)\n",
        "        start += (size / 2)\n",
        "\n",
        "def segment_signal(data,window_size = 90):\n",
        "    segments = np.empty((0,window_size,3))\n",
        "    labels = np.empty((0))\n",
        "    for (start, end) in windows(data['timestamp'], window_size):\n",
        "        x = data[\"x-axis\"][start:end]\n",
        "        y = data[\"y-axis\"][start:end]\n",
        "        z = data[\"z-axis\"][start:end]\n",
        "        if(len(dataset['timestamp'][start:end]) == window_size):\n",
        "            segments = np.vstack([segments,np.dstack([x,y,z])])\n",
        "            labels = np.append(labels,stats.mode(data[\"activity\"][start:end])[0][0])\n",
        "    return segments, labels\n",
        "\n",
        "def weight_variable(shape):\n",
        "    initial = tf.truncated_normal(shape, stddev = 0.1)\n",
        "    return tf.Variable(initial)\n",
        "\n",
        "def bias_variable(shape):\n",
        "    initial = tf.constant(0.0, shape = shape)\n",
        "    return tf.Variable(initial)\n",
        "\n",
        "def depthwise_conv2d(x, W):\n",
        "    return tf.nn.depthwise_conv2d(x,W, [1, 1, 1, 1], padding='VALID')\n",
        "\n",
        "def apply_depthwise_conv(x,kernel_size,num_channels,depth):\n",
        "    weights = weight_variable([1, kernel_size, num_channels, depth])\n",
        "    biases = bias_variable([depth * num_channels])\n",
        "    return tf.nn.relu(tf.add(depthwise_conv2d(x, weights),biases))\n",
        "\n",
        "def apply_max_pool(x,kernel_size,stride_size):\n",
        "    return tf.nn.max_pool(x, ksize=[1, 1, kernel_size, 1],\n",
        "                          strides=[1, 1, stride_size, 1], padding='VALID')"
      ],
      "metadata": {
        "id": "xLtWDa1m3OYX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = read_data('actitracker_raw.txt')\n",
        "dataset['x-axis'] = feature_normalize(dataset['x-axis'])\n",
        "dataset['y-axis'] = feature_normalize(dataset['y-axis'])\n",
        "dataset['z-axis'] = feature_normalize(dataset['z-axis'])"
      ],
      "metadata": {
        "id": "48QXwCHp3Sy2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}